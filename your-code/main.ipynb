{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Lab\n",
    "\n",
    "You will find in this notebook some scrapy exercises to practise your scraping skills.\n",
    "\n",
    "**Tips:**\n",
    "\n",
    "- Check the response status code for each request to ensure you have obtained the intended content.\n",
    "- Print the response text in each request to understand the kind of info you are getting and its format.\n",
    "- Check for patterns in the response text to extract the data/info requested in each question.\n",
    "- Visit the urls below and take a look at their source code through Chrome DevTools. You'll need to identify the html tags, special class names, etc used in the html content you are expected to extract.\n",
    "\n",
    "**Resources**:\n",
    "- [Requests library](http://docs.python-requests.org/en/master/#the-user-guide)\n",
    "- [Beautiful Soup Doc](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Urllib](https://docs.python.org/3/library/urllib.html#module-urllib)\n",
    "- [re lib](https://docs.python.org/3/library/re.html)\n",
    "- [lxml lib](https://lxml.de/)\n",
    "- [Scrapy](https://scrapy.org/)\n",
    "- [List of HTTP status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "- [HTML basics](http://www.simplehtmlguide.com/cheatsheet.php)\n",
    "- [CSS basics](https://www.cssbasics.com/#page_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below are the libraries and modules you may need. `requests`,  `BeautifulSoup` and `pandas` are already imported for you. If you prefer to use additional libraries feel free to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import html5lib\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download, parse (using BeautifulSoup), and print the content from the Trending Developers page from GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/developers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learn & contribute\n",
      "Connect with others\n",
      "Trending\n",
      "\n",
      "      These are the developers building the hot tools today.\n",
      "    \n",
      "\n",
      "\n",
      "            Will McGugan\n",
      " \n",
      "\n",
      "\n",
      "              willmcgugan\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "      rich\n",
      " \n",
      "\n",
      "\n",
      "            Wim\n",
      " \n",
      "\n",
      "\n",
      "              42wim\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "      matterbridge\n",
      " \n",
      "\n",
      "\n",
      "            Alex Fox\n",
      " \n",
      "\n",
      "\n",
      "              alexfoxy\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "      lax.js\n",
      " \n",
      "\n",
      "\n",
      "            Igor Savin\n",
      " \n",
      "\n",
      "\n",
      "              kibertoad\n",
      " \n",
      " Vilnius\n",
      "\n",
      "\n",
      "            Dmitry Patsura\n",
      " \n",
      "\n",
      "\n",
      "              ovr\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "      react-native-status-bar-height\n",
      " \n",
      "\n",
      "\n",
      "            Jan De Dobbeleer\n",
      " \n",
      "\n",
      "\n",
      "              JanDeDobbeleer\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "      oh-my-posh\n",
      " \n",
      "\n",
      "\n",
      "            Michele Locati\n",
      " \n",
      "\n",
      "\n",
      "              mlocati\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "      docker-php-extension-installer\n",
      " \n",
      "\n",
      "\n",
      "            Tim Oliver\n",
      " \n",
      "\n",
      "\n",
      "              TimOliver\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "      TOCropViewController\n",
      " \n",
      "\n",
      "\n",
      "            Frederic Branczyk\n",
      " \n",
      "\n",
      "\n",
      "              brancz\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "      prometheus-example-app\n",
      " \n",
      "\n",
      "\n",
      "            Lee Robinson\n",
      " \n",
      "\n",
      "\n",
      "              leerob\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "      leerob.io\n",
      " \n",
      "\n",
      "\n",
      "            James Newton-King\n",
      " \n",
      "\n",
      "\n",
      "              JamesNK\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "      Newtonsoft.Json\n",
      " \n",
      "\n",
      "\n",
      "            Franck Nijhof\n",
      " \n",
      "\n",
      "\n",
      "              frenck\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "      awesome-home-assistant\n",
      " \n",
      "\n",
      "\n",
      "            Luan Nico\n",
      " \n",
      "\n",
      "\n",
      "              luanpotter\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "      audioplayers\n",
      " \n",
      "\n",
      "\n",
      "            Oskar Dudycz\n",
      " \n",
      "\n",
      "\n",
      "              oskardudycz\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "      ArchitectureWeekly\n",
      " \n",
      "\n",
      "\n",
      "            Dan Davison\n",
      " \n",
      "\n",
      "\n",
      "              dandavison\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "      delta\n",
      " \n",
      "\n",
      "\n",
      "            Kévin Dunglas\n",
      " \n",
      "\n",
      "\n",
      "              dunglas\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "      vulcain\n",
      " \n",
      "\n",
      "\n",
      "            Matt Layher\n",
      " \n",
      "\n",
      "\n",
      "              mdlayher\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "      block\n",
      " \n",
      "\n",
      "\n",
      "            Jason Quense\n",
      " \n",
      "\n",
      "\n",
      "              jquense\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "      yup\n",
      " \n",
      "\n",
      "\n",
      "            Andy Grunwald\n",
      " \n",
      "\n",
      "\n",
      "              andygrunwald\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "      FOM-LaTeX-Template\n",
      " \n",
      "\n",
      "\n",
      "            Vítor Galvão\n",
      " \n",
      "\n",
      "\n",
      "              vitorgalvao\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "      custom-alfred-iterm-scripts\n",
      " \n",
      "\n",
      "\n",
      "            Elad Ben-Israel\n",
      " \n",
      "\n",
      "\n",
      "              eladb\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "      cdk-watchful\n",
      " \n",
      "\n",
      "\n",
      "            Jason Miller\n",
      " \n",
      "\n",
      "\n",
      "              developit\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "      mitt\n",
      " \n",
      "\n",
      "\n",
      "            Harsh Bardhan Mishra\n",
      " \n",
      "\n",
      "\n",
      "              HarshCasper\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "      Rotten-Scripts\n",
      " \n",
      "\n",
      "\n",
      "            Evan Wallace\n",
      " \n",
      "\n",
      "\n",
      "              evanw\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "      esbuild\n",
      " \n",
      "\n",
      "\n",
      "            Fabian Affolter\n",
      " \n",
      "\n",
      "\n",
      "              fabaff\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "      mqtt-panel\n",
      " \n",
      "Product\n",
      "Platform\n",
      "Support\n",
      "Company\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "html = requests.get(url).content\n",
    "\n",
    "# making the \"soup\"\n",
    "soup = BeautifulSoup(html, \"lxml\")\n",
    "\n",
    "# get the content from the header and paragraph tags\n",
    "tags = ['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'h7', 'p']\n",
    "text = [element.text for element in soup.find_all(tags)]\n",
    "\n",
    "# paragraph form viewing\n",
    "print('\\n'.join(text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Display the names of the trending developers retrieved in the previous step.\n",
    "\n",
    "Your output should be a Python list of developer names. Each name should not contain any html tag.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Find out the html tag and class names used for the developer names. You can achieve this using Chrome DevTools or clicking in 'Inspect' on any browser. Here is an example:\n",
    "\n",
    "![title](example_1.png)\n",
    "\n",
    "2. Use BeautifulSoup `find_all()` to extract all the html elements that contain the developer names. Hint: pass in the `attrs` parameter to specify the class.\n",
    "\n",
    "3. Loop through the elements found and get the text for each of them.\n",
    "\n",
    "4. While you are at it, use string manipulation techniques to replace whitespaces and linebreaks (i.e. `\\n`) in the *text* of each html element. Use a list to store the clean names. Hint: you may also use `.get_text()` instead of `.text` and pass in the desired parameters to do some string manipulation (check the documentation).\n",
    "\n",
    "5. Print the list of names.\n",
    "\n",
    "Your output should look like below:\n",
    "\n",
    "```\n",
    "['trimstray (@trimstray)',\n",
    " 'joewalnes (JoeWalnes)',\n",
    " 'charlax (Charles-AxelDein)',\n",
    " 'ForrestKnight (ForrestKnight)',\n",
    " 'revery-ui (revery-ui)',\n",
    " 'alibaba (Alibaba)',\n",
    " 'Microsoft (Microsoft)',\n",
    " 'github (GitHub)',\n",
    " 'facebook (Facebook)',\n",
    " 'boazsegev (Bo)',\n",
    " 'google (Google)',\n",
    " 'cloudfetch',\n",
    " 'sindresorhus (SindreSorhus)',\n",
    " 'tensorflow',\n",
    " 'apache (TheApacheSoftwareFoundation)',\n",
    " 'DevonCrawford (DevonCrawford)',\n",
    " 'ARMmbed (ArmMbed)',\n",
    " 'vuejs (vuejs)',\n",
    " 'fastai (fast.ai)',\n",
    " 'QiShaoXuan (Qi)',\n",
    " 'joelparkerhenderson (JoelParkerHenderson)',\n",
    " 'torvalds (LinusTorvalds)',\n",
    " 'CyC2018',\n",
    " 'komeiji-satori (神楽坂覚々)',\n",
    " 'script-8']\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Will McGugan'],\n",
       " ['Wim'],\n",
       " ['Alex Fox'],\n",
       " ['Igor Savin'],\n",
       " ['Dmitry Patsura'],\n",
       " ['Jan De Dobbeleer'],\n",
       " ['Michele Locati'],\n",
       " ['Tim Oliver'],\n",
       " ['Frederic Branczyk'],\n",
       " ['Lee Robinson'],\n",
       " ['James Newton-King'],\n",
       " ['Franck Nijhof'],\n",
       " ['Luan Nico'],\n",
       " ['Oskar Dudycz'],\n",
       " ['Dan Davison'],\n",
       " ['Kévin Dunglas'],\n",
       " ['Matt Layher'],\n",
       " ['Jason Quense'],\n",
       " ['Andy Grunwald'],\n",
       " ['Vítor Galvão'],\n",
       " ['Elad Ben-Israel'],\n",
       " ['Jason Miller'],\n",
       " ['Harsh Bardhan Mishra'],\n",
       " ['Evan Wallace'],\n",
       " ['Fabian Affolter']]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "full_name = soup.find_all('h1',attrs = {'class': \"h3 lh-condensed\"})\n",
    "\n",
    "list_names = [full_name.get_text().strip().split(\"\\n\") for full_name in soup.find_all('h1',{'class':'h3 lh-condensed'} ) ]\n",
    "\n",
    "list_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Display the trending Python repositories in GitHub.\n",
    "\n",
    "The steps to solve this problem is similar to the previous one except that you need to find out the repository names instead of developer names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/python?since=daily'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['mxrch /\\n\\n      GHunt'],\n",
       " ['ChinaVolvocars /\\n\\n      jd_maotai_seckill'],\n",
       " ['THUMNLab /\\n\\n      AutoGL'],\n",
       " ['huanghyw /\\n\\n      jd_seckill'],\n",
       " ['jerry3747 /\\n\\n      taobao_seckill'],\n",
       " ['owid /\\n\\n      covid-19-data'],\n",
       " ['willmcgugan /\\n\\n      rich'],\n",
       " ['tychxn /\\n\\n      jd-assistant'],\n",
       " ['microsoft /\\n\\n      AI-System'],\n",
       " ['pythonstock /\\n\\n      stock'],\n",
       " ['back8 /\\n\\n      github_huanghyw_jd_seckill'],\n",
       " ['Rapptz /\\n\\n      discord.py'],\n",
       " ['home-assistant /\\n\\n      core'],\n",
       " ['tensorflow /\\n\\n      models'],\n",
       " ['onelivesleft /\\n\\n      PrettyErrors'],\n",
       " ['SleepyBag /\\n\\n      Statistical-Learning-Methods'],\n",
       " ['wlwwu /\\n\\n      jd_maotai'],\n",
       " ['ray-project /\\n\\n      ray'],\n",
       " ['public-apis /\\n\\n      public-apis'],\n",
       " ['jrieke /\\n\\n      traingenerator'],\n",
       " ['opencve /\\n\\n      opencve'],\n",
       " ['boston-dynamics /\\n\\n      spot-sdk'],\n",
       " ['tiangolo /\\n\\n      typer'],\n",
       " ['Zero-S1 /\\n\\n      JD_tools'],\n",
       " ['mingrammer /\\n\\n      diagrams']]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "html = requests.get(url).content\n",
    "\n",
    "# making the \"soup\"\n",
    "soup = BeautifulSoup(html, features = \"lxml\")\n",
    "\n",
    "# after inspecting, getting the repos name\n",
    "repo = soup.find_all(\"h1\",attrs = {\"class\": \"h3 lh-condensed\"})[0]\n",
    "                                  \n",
    "repos = [repo.get_text().strip().split(\"\\t\\n\\r\") for repo in soup.find_all('h1',attrs = {'class':\"h3 lh-condensed\"} ) ]\n",
    "\n",
    "repos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Display all the image links from Walt Disney wikipedia page.\n",
    "Hint: use `.get()` to access information inside tags. Check out the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://en.wikipedia.org/wiki/Walt_Disney'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<img alt=\"\" class=\"thumbimage\" data-file-height=\"1086\" data-file-width=\"1576\" decoding=\"async\" height=\"152\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/c/c4/Walt_Disney_envelope_ca._1921.jpg/220px-Walt_Disney_envelope_ca._1921.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/c/c4/Walt_Disney_envelope_ca._1921.jpg/330px-Walt_Disney_envelope_ca._1921.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/c/c4/Walt_Disney_envelope_ca._1921.jpg/440px-Walt_Disney_envelope_ca._1921.jpg 2x\" width=\"220\"/>,\n",
       " <img alt=\"File:Newman Laugh-O-Gram (1921).webm\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Newman_Laugh-O-Gram_%281921%29.webm/220px-seek%3D2-Newman_Laugh-O-Gram_%281921%29.webm.jpg\" style=\"width:220px;height:165px\"/>,\n",
       " <img alt=\"A cartoon rabbit is driving a tramcar; other cartoon rabbits are in, under, on and around the car.\" class=\"thumbimage\" data-file-height=\"1600\" data-file-width=\"1202\" decoding=\"async\" height=\"226\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Trolley_Troubles_poster.jpg/170px-Trolley_Troubles_poster.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Trolley_Troubles_poster.jpg/255px-Trolley_Troubles_poster.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Trolley_Troubles_poster.jpg/340px-Trolley_Troubles_poster.jpg 2x\" width=\"170\"/>,\n",
       " <img alt=\"Walt Disney with Mickey Mouse\" class=\"thumbimage\" data-file-height=\"1028\" data-file-width=\"915\" decoding=\"async\" height=\"191\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/7/71/Walt_Disney_and_his_cartoon_creation_%22Mickey_Mouse%22_-_National_Board_of_Review_Magazine.jpg/170px-Walt_Disney_and_his_cartoon_creation_%22Mickey_Mouse%22_-_National_Board_of_Review_Magazine.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/7/71/Walt_Disney_and_his_cartoon_creation_%22Mickey_Mouse%22_-_National_Board_of_Review_Magazine.jpg/255px-Walt_Disney_and_his_cartoon_creation_%22Mickey_Mouse%22_-_National_Board_of_Review_Magazine.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/7/71/Walt_Disney_and_his_cartoon_creation_%22Mickey_Mouse%22_-_National_Board_of_Review_Magazine.jpg/340px-Walt_Disney_and_his_cartoon_creation_%22Mickey_Mouse%22_-_National_Board_of_Review_Magazine.jpg 2x\" width=\"170\"/>,\n",
       " <img alt=\"A cartoon mouse is operating a ship's steering wheel\" class=\"thumbimage\" data-file-height=\"267\" data-file-width=\"373\" decoding=\"async\" height=\"122\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/4/4e/Steamboat-willie.jpg/170px-Steamboat-willie.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/en/thumb/4/4e/Steamboat-willie.jpg/255px-Steamboat-willie.jpg 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/4/4e/Steamboat-willie.jpg/340px-Steamboat-willie.jpg 2x\" width=\"170\"/>,\n",
       " <img alt=\"\" class=\"thumbimage\" data-file-height=\"451\" data-file-width=\"358\" decoding=\"async\" height=\"214\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/5/57/Walt_Disney_1935.jpg/170px-Walt_Disney_1935.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/5/57/Walt_Disney_1935.jpg/255px-Walt_Disney_1935.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/5/57/Walt_Disney_1935.jpg/340px-Walt_Disney_1935.jpg 2x\" width=\"170\"/>,\n",
       " <img alt=\"Walt Disney sits in front of a set of models of the seven dwarfs\" class=\"thumbimage\" data-file-height=\"388\" data-file-width=\"500\" decoding=\"async\" height=\"171\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Walt_Disney_Snow_white_1937_trailer_screenshot_%2813%29.jpg/220px-Walt_Disney_Snow_white_1937_trailer_screenshot_%2813%29.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Walt_Disney_Snow_white_1937_trailer_screenshot_%2813%29.jpg/330px-Walt_Disney_Snow_white_1937_trailer_screenshot_%2813%29.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Walt_Disney_Snow_white_1937_trailer_screenshot_%2813%29.jpg/440px-Walt_Disney_Snow_white_1937_trailer_screenshot_%2813%29.jpg 2x\" width=\"220\"/>,\n",
       " <img alt=\"\" class=\"thumbimage\" data-file-height=\"770\" data-file-width=\"600\" decoding=\"async\" height=\"218\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/1/15/Disney_drawing_goofy.jpg/170px-Disney_drawing_goofy.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/1/15/Disney_drawing_goofy.jpg/255px-Disney_drawing_goofy.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/1/15/Disney_drawing_goofy.jpg/340px-Disney_drawing_goofy.jpg 2x\" width=\"170\"/>,\n",
       " <img alt=\"\" class=\"thumbimage\" data-file-height=\"2493\" data-file-width=\"3247\" decoding=\"async\" height=\"169\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/1/13/DisneySchiphol1951.jpg/220px-DisneySchiphol1951.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/1/13/DisneySchiphol1951.jpg/330px-DisneySchiphol1951.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/1/13/DisneySchiphol1951.jpg/440px-DisneySchiphol1951.jpg 2x\" width=\"220\"/>,\n",
       " <img alt=\"\" class=\"thumbimage\" data-file-height=\"2417\" data-file-width=\"2723\" decoding=\"async\" height=\"195\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/8/8c/WaltDisneyplansDisneylandDec1954.jpg/220px-WaltDisneyplansDisneylandDec1954.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/8/8c/WaltDisneyplansDisneylandDec1954.jpg/330px-WaltDisneyplansDisneylandDec1954.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/8/8c/WaltDisneyplansDisneylandDec1954.jpg/440px-WaltDisneyplansDisneylandDec1954.jpg 2x\" width=\"220\"/>,\n",
       " <img alt=\"\" class=\"thumbimage\" data-file-height=\"902\" data-file-width=\"667\" decoding=\"async\" height=\"230\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/f/ff/Walt_disney_portrait_right.jpg/170px-Walt_disney_portrait_right.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/f/ff/Walt_disney_portrait_right.jpg/255px-Walt_disney_portrait_right.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/f/ff/Walt_disney_portrait_right.jpg/340px-Walt_disney_portrait_right.jpg 2x\" width=\"170\"/>,\n",
       " <img alt=\"\" class=\"thumbimage\" data-file-height=\"275\" data-file-width=\"220\" decoding=\"async\" height=\"213\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/2/2d/Roy_O._Disney_with_Company_at_Press_Conference.jpg/170px-Roy_O._Disney_with_Company_at_Press_Conference.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/commons/2/2d/Roy_O._Disney_with_Company_at_Press_Conference.jpg 1.5x\" width=\"170\"/>,\n",
       " <img alt=\"A portrait of Disney with cartoon representations of different nationalities on a 6 cent US stamp\" class=\"thumbimage\" data-file-height=\"736\" data-file-width=\"483\" decoding=\"async\" height=\"259\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/6c/Disney1968.jpg/170px-Disney1968.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/6c/Disney1968.jpg/255px-Disney1968.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/6/6c/Disney1968.jpg/340px-Disney1968.jpg 2x\" width=\"170\"/>,\n",
       " <img alt=\"Magic Kingdom castle.jpg\" data-file-height=\"1545\" data-file-width=\"1262\" decoding=\"async\" height=\"30\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Magic_Kingdom_castle.jpg/24px-Magic_Kingdom_castle.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Magic_Kingdom_castle.jpg/37px-Magic_Kingdom_castle.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Magic_Kingdom_castle.jpg/49px-Magic_Kingdom_castle.jpg 2x\" width=\"24\"/>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = response.content\n",
    "\n",
    "soup = BeautifulSoup(html, features = \"lxml\")\n",
    "\n",
    "images = soup.find_all('img', {'src':re.compile('.jpg')})\n",
    "\n",
    "images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. List all language names and number of related articles in the order they appear in wikipedia.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.wikipedia.org/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"central-featured-lang lang1\" dir=\"ltr\" lang=\"en\">\n",
       " <a class=\"link-box\" data-slogan=\"The Free Encyclopedia\" href=\"//en.wikipedia.org/\" id=\"js-link-box-en\" title=\"English — Wikipedia — The Free Encyclopedia\">\n",
       " <strong>English</strong>\n",
       " <small><bdi dir=\"ltr\">6 207 000+</bdi> <span>articles</span></small>\n",
       " </a>\n",
       " </div>,\n",
       " <div class=\"central-featured-lang lang2\" dir=\"ltr\" lang=\"es\">\n",
       " <a class=\"link-box\" data-slogan=\"La enciclopedia libre\" href=\"//es.wikipedia.org/\" id=\"js-link-box-es\" title=\"Español — Wikipedia — La enciclopedia libre\">\n",
       " <strong>Español</strong>\n",
       " <small><bdi dir=\"ltr\">1 646 000+</bdi> <span>artículos</span></small>\n",
       " </a>\n",
       " </div>,\n",
       " <div class=\"central-featured-lang lang3\" dir=\"ltr\" lang=\"ja\">\n",
       " <a class=\"link-box\" data-slogan=\"フリー百科事典\" href=\"//ja.wikipedia.org/\" id=\"js-link-box-ja\" title=\"Nihongo — ウィキペディア — フリー百科事典\">\n",
       " <strong>日本語</strong>\n",
       " <small><bdi dir=\"ltr\">1 243 000+</bdi> <span>記事</span></small>\n",
       " </a>\n",
       " </div>,\n",
       " <div class=\"central-featured-lang lang4\" dir=\"ltr\" lang=\"de\">\n",
       " <a class=\"link-box\" data-slogan=\"Die freie Enzyklopädie\" href=\"//de.wikipedia.org/\" id=\"js-link-box-de\" title=\"Deutsch — Wikipedia — Die freie Enzyklopädie\">\n",
       " <strong>Deutsch</strong>\n",
       " <small><bdi dir=\"ltr\">2 510 000+</bdi> <span>Artikel</span></small>\n",
       " </a>\n",
       " </div>,\n",
       " <div class=\"central-featured-lang lang5\" dir=\"ltr\" lang=\"ru\">\n",
       " <a class=\"link-box\" data-slogan=\"Свободная энциклопедия\" href=\"//ru.wikipedia.org/\" id=\"js-link-box-ru\" title=\"Russkiy — Википедия — Свободная энциклопедия\">\n",
       " <strong>Русский</strong>\n",
       " <small><bdi dir=\"ltr\">1 682 000+</bdi> <span>статей</span></small>\n",
       " </a>\n",
       " </div>,\n",
       " <div class=\"central-featured-lang lang6\" dir=\"ltr\" lang=\"fr\">\n",
       " <a class=\"link-box\" data-slogan=\"L’encyclopédie libre\" href=\"//fr.wikipedia.org/\" id=\"js-link-box-fr\" title=\"Français — Wikipédia — L’encyclopédie libre\">\n",
       " <strong>Français</strong>\n",
       " <small><bdi dir=\"ltr\">2 277 000+</bdi> <span>articles</span></small>\n",
       " </a>\n",
       " </div>,\n",
       " <div class=\"central-featured-lang lang7\" dir=\"ltr\" lang=\"it\">\n",
       " <a class=\"link-box\" data-slogan=\"L'enciclopedia libera\" href=\"//it.wikipedia.org/\" id=\"js-link-box-it\" title=\"Italiano — Wikipedia — L'enciclopedia libera\">\n",
       " <strong>Italiano</strong>\n",
       " <small><bdi dir=\"ltr\">1 658 000+</bdi> <span>voci</span></small>\n",
       " </a>\n",
       " </div>,\n",
       " <div class=\"central-featured-lang lang8\" dir=\"ltr\" lang=\"zh\">\n",
       " <a class=\"link-box\" data-converttitle-hans=\"Zhōngwén — 维基百科 — 自由的百科全书\" data-slogan=\"自由的百科全書\" href=\"//zh.wikipedia.org/\" id=\"js-link-box-zh\" title=\"Zhōngwén — 維基百科 — 自由的百科全書\">\n",
       " <strong>中文</strong>\n",
       " <small><bdi dir=\"ltr\">1 163 000+</bdi> <span data-convert-hans=\"条目\" id=\"zh_art\">條目</span></small>\n",
       " </a>\n",
       " </div>,\n",
       " <div class=\"central-featured-lang lang9\" dir=\"ltr\" lang=\"pt\">\n",
       " <a class=\"link-box\" data-slogan=\"A enciclopédia livre\" href=\"//pt.wikipedia.org/\" id=\"js-link-box-pt\" title=\"Português — Wikipédia — A enciclopédia livre\">\n",
       " <strong>Português</strong>\n",
       " <small><bdi dir=\"ltr\">1 049 000+</bdi> <span>artigos</span></small>\n",
       " </a>\n",
       " </div>,\n",
       " <div class=\"central-featured-lang lang10\" dir=\"ltr\" lang=\"pl\">\n",
       " <a class=\"link-box\" data-slogan=\"Wolna encyklopedia\" href=\"//pl.wikipedia.org/\" id=\"js-link-box-pl\" title=\"Polski — Wikipedia — Wolna encyklopedia\">\n",
       " <strong>Polski</strong>\n",
       " <small><bdi dir=\"ltr\">1 444 000+</bdi> <span>haseł</span></small>\n",
       " </a>\n",
       " </div>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "html = response.content\n",
    "\n",
    "# making the \"soup\"\n",
    "\n",
    "soup = BeautifulSoup(html, features = \"lxml\")\n",
    "\n",
    "# after inspecting, getting the languages list\n",
    "\n",
    "languages = soup.find_all(\"div\", attrs = {re.compile(\"central-featured-lang\")})\n",
    "\n",
    "languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "English\n",
      "6 207 000+ articles\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Español\n",
      "1 646 000+ artículos\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "日本語\n",
      "1 243 000+ 記事\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Deutsch\n",
      "2 510 000+ Artikel\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Русский\n",
      "1 682 000+ статей\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Français\n",
      "2 277 000+ articles\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Italiano\n",
      "1 658 000+ voci\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "中文\n",
      "1 163 000+ 條目\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Português\n",
      "1 049 000+ artigos\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Polski\n",
      "1 444 000+ haseł\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "languages_list = []\n",
    "\n",
    "for language in languages:\n",
    "    print(language.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Display the top 10 languages by number of native speakers stored in a pandas dataframe.\n",
    "Hint: After finding the correct table you want to analyse, you can use a nested **for** loop to find the elements row by row (check out the 'td' and 'tr' tags). <br>An easier way to do it is using pd.read_html(), check out documentation [here](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.read_html.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Language</th>\n",
       "      <th>Speakers(millions)</th>\n",
       "      <th>Percentageof world pop.(March 2019)[8]</th>\n",
       "      <th>Language family</th>\n",
       "      <th>Branch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mandarin Chinese</td>\n",
       "      <td>918.0</td>\n",
       "      <td>11.922%</td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "      <td>Sinitic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>480.0</td>\n",
       "      <td>5.994%</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>English</td>\n",
       "      <td>379.0</td>\n",
       "      <td>4.922%</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Hindi (sanskritised Hindustani)[9]</td>\n",
       "      <td>341.0</td>\n",
       "      <td>4.429%</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Indo-Aryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Bengali</td>\n",
       "      <td>228.0</td>\n",
       "      <td>2.961%</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Indo-Aryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>87</td>\n",
       "      <td>Czech</td>\n",
       "      <td>10.7</td>\n",
       "      <td>0.139%</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Balto-Slavic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>88</td>\n",
       "      <td>Taʽizzi-Adeni Arabic</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.136%</td>\n",
       "      <td>Afroasiatic</td>\n",
       "      <td>Semitic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>89</td>\n",
       "      <td>Uyghur</td>\n",
       "      <td>10.4</td>\n",
       "      <td>0.135%</td>\n",
       "      <td>Turkic</td>\n",
       "      <td>Karluk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>90</td>\n",
       "      <td>Min Dong Chinese</td>\n",
       "      <td>10.3</td>\n",
       "      <td>0.134%</td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "      <td>Sinitic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>91</td>\n",
       "      <td>Sylheti</td>\n",
       "      <td>10.3</td>\n",
       "      <td>0.134%</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Indo-Aryan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                            Language  Speakers(millions)  \\\n",
       "0      1                    Mandarin Chinese               918.0   \n",
       "1      2                             Spanish               480.0   \n",
       "2      3                             English               379.0   \n",
       "3      4  Hindi (sanskritised Hindustani)[9]               341.0   \n",
       "4      5                             Bengali               228.0   \n",
       "..   ...                                 ...                 ...   \n",
       "86    87                               Czech                10.7   \n",
       "87    88                Taʽizzi-Adeni Arabic                10.5   \n",
       "88    89                              Uyghur                10.4   \n",
       "89    90                    Min Dong Chinese                10.3   \n",
       "90    91                             Sylheti                10.3   \n",
       "\n",
       "   Percentageof world pop.(March 2019)[8] Language family        Branch  \n",
       "0                                 11.922%    Sino-Tibetan       Sinitic  \n",
       "1                                  5.994%   Indo-European       Romance  \n",
       "2                                  4.922%   Indo-European      Germanic  \n",
       "3                                  4.429%   Indo-European    Indo-Aryan  \n",
       "4                                  2.961%   Indo-European    Indo-Aryan  \n",
       "..                                    ...             ...           ...  \n",
       "86                                 0.139%   Indo-European  Balto-Slavic  \n",
       "87                                 0.136%     Afroasiatic       Semitic  \n",
       "88                                 0.135%          Turkic        Karluk  \n",
       "89                                 0.134%    Sino-Tibetan       Sinitic  \n",
       "90                                 0.134%   Indo-European    Indo-Aryan  \n",
       "\n",
       "[91 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "table = pd.read_html(url)\n",
    "\n",
    "table[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Display IMDB's top 250 data (movie name, initial release, director name and stars) as a pandas dataframe.\n",
    "Hint: If you hover over the title of the movie, you should see the director's name. Can you find where it's stored in the html?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "url = 'https://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Rank &amp; Title</th>\n",
       "      <th>IMDb Rating</th>\n",
       "      <th>Your Rating</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.  Cadena perpetua  (1994)</td>\n",
       "      <td>9.2</td>\n",
       "      <td>12345678910 NOT YET RELEASED  Seen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.  El padrino  (1972)</td>\n",
       "      <td>9.1</td>\n",
       "      <td>12345678910 NOT YET RELEASED  Seen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.  El padrino: Parte II  (1974)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12345678910 NOT YET RELEASED  Seen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.  El caballero oscuro  (2008)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12345678910 NOT YET RELEASED  Seen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.  12 hombres sin piedad  (1957)</td>\n",
       "      <td>8.9</td>\n",
       "      <td>12345678910 NOT YET RELEASED  Seen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>NaN</td>\n",
       "      <td>246.  Drishyam  (2015)</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12345678910 NOT YET RELEASED  Seen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>NaN</td>\n",
       "      <td>247.  La princesa prometida  (1987)</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12345678910 NOT YET RELEASED  Seen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>NaN</td>\n",
       "      <td>248.  La batalla de Argel  (1966)</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12345678910 NOT YET RELEASED  Seen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>NaN</td>\n",
       "      <td>249.  Winter Sleep (Sueño de invierno)  (2014)</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12345678910 NOT YET RELEASED  Seen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>NaN</td>\n",
       "      <td>250.  Mandarinas  (2013)</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12345678910 NOT YET RELEASED  Seen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                    Rank & Title  IMDb Rating  \\\n",
       "0           NaN                     1.  Cadena perpetua  (1994)          9.2   \n",
       "1           NaN                          2.  El padrino  (1972)          9.1   \n",
       "2           NaN                3.  El padrino: Parte II  (1974)          9.0   \n",
       "3           NaN                 4.  El caballero oscuro  (2008)          9.0   \n",
       "4           NaN               5.  12 hombres sin piedad  (1957)          8.9   \n",
       "..          ...                                             ...          ...   \n",
       "245         NaN                          246.  Drishyam  (2015)          8.0   \n",
       "246         NaN             247.  La princesa prometida  (1987)          8.0   \n",
       "247         NaN               248.  La batalla de Argel  (1966)          8.0   \n",
       "248         NaN  249.  Winter Sleep (Sueño de invierno)  (2014)          8.0   \n",
       "249         NaN                        250.  Mandarinas  (2013)          8.0   \n",
       "\n",
       "                            Your Rating  Unnamed: 4  \n",
       "0    12345678910 NOT YET RELEASED  Seen         NaN  \n",
       "1    12345678910 NOT YET RELEASED  Seen         NaN  \n",
       "2    12345678910 NOT YET RELEASED  Seen         NaN  \n",
       "3    12345678910 NOT YET RELEASED  Seen         NaN  \n",
       "4    12345678910 NOT YET RELEASED  Seen         NaN  \n",
       "..                                  ...         ...  \n",
       "245  12345678910 NOT YET RELEASED  Seen         NaN  \n",
       "246  12345678910 NOT YET RELEASED  Seen         NaN  \n",
       "247  12345678910 NOT YET RELEASED  Seen         NaN  \n",
       "248  12345678910 NOT YET RELEASED  Seen         NaN  \n",
       "249  12345678910 NOT YET RELEASED  Seen         NaN  \n",
       "\n",
       "[250 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "data = pd.read_html (url)\n",
    "\n",
    "data [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Display the movie name, year and a brief summary of the top 10 random movies (IMDB) as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the url you will scrape in this exercise\n",
    "url = 'https://www.imdb.com/list/ls009796553/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: 'chromedriver.exe' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/selenium/webdriver/common/service.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mcmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_line_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             self.process = subprocess.Popen(cmd, env=self.env,\n\u001b[0m\u001b[1;32m     73\u001b[0m                                             \u001b[0mclose_fds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplatform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'Windows'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.8/3.8.5/Frameworks/Python.framework/Versions/3.8/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[1;32m    855\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.8/3.8.5/Frameworks/Python.framework/Versions/3.8/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1701\u001b[0m                         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1702\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1703\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/chromedriver_win32/chromedriver.exe'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-271332aed004>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# your code here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'C:/chromedriver_win32/chromedriver.exe'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/selenium/webdriver/chrome/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, keep_alive)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mservice_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mservice_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             log_path=service_log_path)\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/selenium/webdriver/common/service.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 raise WebDriverException(\n\u001b[0m\u001b[1;32m     82\u001b[0m                     \"'%s' executable needs to be in PATH. %s\" % (\n\u001b[1;32m     83\u001b[0m                         os.path.basename(self.path), self.start_error_message)\n",
      "\u001b[0;31mWebDriverException\u001b[0m: Message: 'chromedriver.exe' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "driver = webdriver.Chrome('C:/chromedriver_win32/chromedriver.exe')\n",
    "driver.get(url)\n",
    "html = driver.page_source\n",
    "\n",
    "movies = pd.read_html (htm)\n",
    "\n",
    "movies[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the live weather report (temperature, wind speed, description and weather) of a given city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-0299fa35631a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#https://openweathermap.org/current\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Enter the city: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'http://api.openweathermap.org/data/2.5/weather?'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'q='\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcity\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'&APPID=b35975e18dc93725acb092f7272cc6b8&units=metric'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             )\n\u001b[0;32m--> 860\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "#https://openweathermap.org/current\n",
    "city = input('Enter the city: ')\n",
    "url = 'http://api.openweathermap.org/data/2.5/weather?'+'q='+city+'&APPID=b35975e18dc93725acb092f7272cc6b8&units=metric'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the book name, price and stock availability as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise. \n",
    "# It is a fictional bookstore created to be scraped. \n",
    "url = 'http://books.toscrape.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Display the 100 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe.\n",
    "***Hint:*** Here the displayed number of earthquakes per page is 20, but you can easily move to the next page by looping through the desired number of pages and adding it to the end of the url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.emsc-csem.org/Earthquake/?view='\n",
    "\n",
    "# This is how you will loop through each page:\n",
    "number_of_pages = int(100/20)\n",
    "each_page_urls = []\n",
    "\n",
    "for n in range(1, number_of_pages+1):\n",
    "    link = url+str(n)\n",
    "    each_page_urls.append(link)\n",
    "    \n",
    "each_page_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
